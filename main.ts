// Deno Deploy å…¥å£æ–‡ä»¶
// ç®€åŒ–ç‰ˆæœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´éƒ¨ç½²å¤±è´¥çš„å¤æ‚åŠŸèƒ½

import { Application, Router } from "https://deno.land/x/oak@v12.6.1/mod.ts";

const BASE_URL = "https://api.bytez.com/models/v2/openai/v1/completions";

interface CompletionRequest {
  model: string;
  prompt: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
}

const router = new Router();

// å¥åº·æ£€æŸ¥
router.get("/", (ctx) => {
  ctx.response.body = {
    status: "ok",
    service: "bytez-openai-proxy",
    version: "1.0.0",
    message: "æœåŠ¡è¿è¡Œæ­£å¸¸"
  };
});

// è·å–æ¨¡å‹åˆ—è¡¨
router.get("/v1/models", (ctx) => {
  const models = [
    { 
      id: "openai-community/gpt2", 
      object: "model", 
      created: 1234567890, 
      owned_by: "bytez" 
    },
  ];
  ctx.response.body = { object: "list", data: models };
});

// æ–‡æœ¬è¡¥å…¨ API
router.post("/v1/completions", async (ctx) => {
  const authorization = ctx.request.headers.get("authorization");
  if (!authorization || !authorization.startsWith("BYTEZ_KEY ")) {
    ctx.response.status = 401;
    ctx.response.body = { error: "éœ€è¦ BYTEZ_KEY è®¤è¯" };
    return;
  }

  let requestData: CompletionRequest;
  try {
    requestData = await ctx.request.body({ type: "json" }).value;
  } catch (e) {
    ctx.response.status = 400;
    ctx.response.body = { error: `æ— æ•ˆçš„ JSON: ${e}` };
    return;
  }

  const model = requestData.model || "openai-community/gpt2";
  const prompt = requestData.prompt || "";
  const stream = requestData.stream || false;

  if (!prompt.trim()) {
    ctx.response.status = 400;
    ctx.response.body = { error: "prompt ä¸èƒ½ä¸ºç©º" };
    return;
  }

  // ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è¿”å›æ¨¡æ‹Ÿå“åº”
  const requestId = `completion-${Date.now()}`;
  
  if (stream) {
    ctx.response.headers.set("Content-Type", "text/event-stream; charset=utf-8");
    ctx.response.headers.set("Cache-Control", "no-cache");
    ctx.response.headers.set("Connection", "keep-alive");
    
    // ç®€åŒ–æµå¼å“åº”
    const encoder = new TextEncoder();
    const body = new ReadableStream({
      async start(controller) {
        const chunks = [
          `data: {"id":"${requestId}","object":"text_completion.chunk","created":${Math.floor(Date.now()/1000)},"model":"${model}","choices":[{"text":"","index":0,"finish_reason":null}]}\n\n`,
          `data: {"id":"${requestId}","object":"text_completion.chunk","created":${Math.floor(Date.now()/1000)},"model":"${model}","choices":[{"text":"è¿™æ˜¯æ¨¡æ‹Ÿå“åº”","index":0,"finish_reason":null}]}\n\n`,
          `data: [DONE]\n\n`
        ];
        
        for (const chunk of chunks) {
          controller.enqueue(encoder.encode(chunk));
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        controller.close();
      }
    });
    
    ctx.response.body = body;
  } else {
    // éæµå¼å“åº”
    ctx.response.body = {
      id: requestId,
      object: "text_completion",
      created: Math.floor(Date.now() / 1000),
      model,
      choices: [
        {
          text: "è¿™æ˜¯æ¨¡æ‹Ÿçš„æ–‡æœ¬è¡¥å…¨å“åº”",
          index: 0,
          finish_reason: "stop",
        },
      ],
      usage: {
        prompt_tokens: prompt.length,
        completion_tokens: 10,
        total_tokens: prompt.length + 10,
      },
    };
  }
});

const app = new Application();

// æ—¥å¿—ä¸­é—´ä»¶
app.use(async (ctx, next) => {
  const start = Date.now();
  await next();
  const ms = Date.now() - start;
  console.log(`${ctx.request.method} ${ctx.request.url} - ${ms}ms`);
});

// é”™è¯¯å¤„ç†ä¸­é—´ä»¶
app.use(async (ctx, next) => {
  try {
    await next();
  } catch (err) {
    console.error("é”™è¯¯:", err);
    ctx.response.status = 500;
    ctx.response.body = { error: "Internal Server Error" };
  }
});

app.use(router.routes());
app.use(router.allowedMethods());

const port = parseInt(Deno.env.get("PORT") || "8000");

console.log(`ğŸš€ æœåŠ¡å™¨è¿è¡Œåœ¨ç«¯å£ ${port}`);
console.log(`ğŸ“š Bytez-OpenAI-Proxy v1.0.0 (Deno Deploy ç‰ˆæœ¬)`);

await app.listen({ port });